{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import pandas as pd\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import os\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "import torchvision\n",
    "import random\n",
    "import wandb\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Step 1: Prepare your dataset\n",
    "class SketchDataset(Dataset):\n",
    "    def __init__(self, csv_file, image_root_dir, sketch_root_dir, transform=None):\n",
    "        \n",
    "        self.data_frame = pd.read_csv(csv_file)\n",
    "        self.image_root_dir = image_root_dir\n",
    "        self.sketch_root_dir = sketch_root_dir\n",
    "        self.transform = transform\n",
    "        self.num_sketches = 3594  # Update with the actual number of sketches\n",
    "        self.num_samples = len(self.data_frame)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_samples\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # print(\"idx: \",idx)\n",
    "        img_name = os.path.join(self.image_root_dir, self.data_frame.iloc[idx, 0] + '.jpg')\n",
    "        sketch_idx = idx % self.num_sketches  # Cyclic indexing for sketches\n",
    "        # print(sketch_idx)\n",
    "        sketch_name = os.path.join(self.sketch_root_dir, f\"sketch_{sketch_idx + 1}.png\")\n",
    "        \n",
    "        image = Image.open(img_name).convert('RGB')\n",
    "        sketch = Image.open(sketch_name).convert('RGB')\n",
    "\n",
    "        label = torch.tensor(self.data_frame.iloc[idx, 1:], dtype=torch.float32)\n",
    "\n",
    "        rand_idx= random.randint(0, self.num_samples-1)\n",
    "        rand_label = torch.tensor(self.data_frame.iloc[rand_idx, 1:], dtype=torch.float32)\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            sketch = self.transform(sketch)\n",
    "        \n",
    "        return label, sketch, image,img_name, rand_label\n",
    "\n",
    "# transform = transforms.Compose([\n",
    "#     transforms.Resize((256,256)),\n",
    "#     transforms.ToTensor(),\n",
    "# ])\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.RandomHorizontalFlip(),  # Random horizontal flip\n",
    "    transforms.RandomRotation(15),       # Random rotation up to 15 degrees\n",
    "    transforms.RandomResizedCrop(256, scale=(0.8, 1.0), ratio=(0.75, 1.333)),  # Random resize and crop\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])  # Normalize to [-1, 1]\n",
    "])\n",
    "\n",
    "\n",
    "# Modify paths as needed\n",
    "train_dataset = SketchDataset(csv_file = '/home/cvlab/Karan/A_3/Dataset_A4/Train_labels.csv', \n",
    "                              image_root_dir = '/home/cvlab/Karan/A_3/Dataset_A4/Train_data',\n",
    "                              sketch_root_dir = '/home/cvlab/Karan/A_3/Dataset_A4/Unpaired_sketch',\n",
    "                              transform = transform)\n",
    "dataloader = DataLoader(train_dataset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, in_channels=3):\n",
    "        super(Discriminator, self).__init__()\n",
    "        # self.ngpu = ngpu\n",
    "        num_classes=7\n",
    "        self.conv1 = nn.Sequential(\n",
    "                    nn.Conv2d(10, 16, 3, 2, 1, bias=False),\n",
    "                    nn.LeakyReLU(0.2, inplace=True),\n",
    "                    nn.Dropout(0.5, inplace=False),\n",
    "                )\n",
    "        # Convolution 2\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(16, 32, 3, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Dropout(0.5, inplace=False),\n",
    "        )\n",
    "        # Convolution 3\n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv2d(32, 64, 3, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Dropout(0.5, inplace=False),\n",
    "        )\n",
    "        # Convolution 4\n",
    "        self.conv4 = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, 3, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Dropout(0.5, inplace=False),\n",
    "        )\n",
    "        # Convolution 5\n",
    "        self.conv5 = nn.Sequential(\n",
    "            nn.Conv2d(128, 256, 3, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Dropout(0.5, inplace=False),\n",
    "        )\n",
    "        # Convolution 6\n",
    "        self.conv6 = nn.Sequential(\n",
    "            nn.Conv2d(256, 512, 3, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Dropout(0.5, inplace=False),\n",
    "        )\n",
    "        # discriminator fc\n",
    "        self.fc_dis = nn.Linear(29*29*512, 1)\n",
    "        # aux-classifier fc\n",
    "        self.fc_aux = nn.Linear(29*29*512, num_classes)\n",
    "        # softmax and sigmoid\n",
    "        self.softmax = nn.Softmax()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, input):\n",
    "        # print(\"input: \",input.shape)\n",
    "        conv1 = self.conv1(input)\n",
    "        # print(\"conv1: \",conv1.shape)\n",
    "        conv2 = self.conv2(conv1)\n",
    "        conv3 = self.conv3(conv2)\n",
    "        conv4 = self.conv4(conv3)\n",
    "        conv5 = self.conv5(conv4)\n",
    "        conv6 = self.conv6(conv5)\n",
    "        # print(\"conv6: \",conv6.shape)\n",
    "        flat6 = conv6.view(-1, 29*29*512)\n",
    "        fc_dis = self.fc_dis(flat6)\n",
    "        fc_aux = self.fc_aux(flat6)\n",
    "        classes = self.softmax(fc_aux)\n",
    "        realfake = self.sigmoid(fc_dis).view(-1, 1).squeeze(1)\n",
    "        # print(\"realfake: \",realfake.shape)\n",
    "        # print(\"classes: \",classes.shape)\n",
    "        return realfake, classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Block(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, down=True, act=\"relu\", use_dropout=False):\n",
    "        super(Block, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, 4, 2, 1, bias=False, padding_mode=\"reflect\")\n",
    "            if down\n",
    "            else nn.ConvTranspose2d(in_channels, out_channels, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU() if act == \"relu\" else nn.LeakyReLU(0.2),\n",
    "        )\n",
    "\n",
    "        self.use_dropout = use_dropout\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.down = down\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        return self.dropout(x) if self.use_dropout else x\n",
    "\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, in_channels=10, features=64): # 3 earlier\n",
    "        super().__init__()\n",
    "        self.initial_down = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, features, 4, 2, 1, padding_mode=\"reflect\"),\n",
    "            nn.LeakyReLU(0.2),\n",
    "        )\n",
    "        self.down1 = Block(features, features * 2, down=True, act=\"leaky\", use_dropout=False)\n",
    "        self.down2 = Block(\n",
    "            features * 2, features * 4, down=True, act=\"leaky\", use_dropout=False\n",
    "        )\n",
    "        self.down3 = Block(\n",
    "            features * 4, features * 8, down=True, act=\"leaky\", use_dropout=False\n",
    "        )\n",
    "        self.down4 = Block(\n",
    "            features * 8, features * 8, down=True, act=\"leaky\", use_dropout=False\n",
    "        )\n",
    "        self.down5 = Block(\n",
    "            features * 8, features * 8, down=True, act=\"leaky\", use_dropout=False\n",
    "        )\n",
    "        self.down6 = Block(\n",
    "            features * 8, features * 8, down=True, act=\"leaky\", use_dropout=False\n",
    "        )\n",
    "        self.bottleneck = nn.Sequential(\n",
    "            nn.Conv2d(features * 8, features * 8, 4, 2, 1), nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.up1 = Block(features * 8, features * 8, down=False, act=\"relu\", use_dropout=True)\n",
    "        self.up2 = Block(\n",
    "            features * 8 * 2, features * 8, down=False, act=\"relu\", use_dropout=True\n",
    "        )\n",
    "        self.up3 = Block(\n",
    "            features * 8 * 2, features * 8, down=False, act=\"relu\", use_dropout=True\n",
    "        )\n",
    "        self.up4 = Block(\n",
    "            features * 8 * 2, features * 8, down=False, act=\"relu\", use_dropout=False\n",
    "        )\n",
    "        self.up5 = Block(\n",
    "            features * 8 * 2, features * 4, down=False, act=\"relu\", use_dropout=False\n",
    "        )\n",
    "        self.up6 = Block(\n",
    "            features * 4 * 2, features * 2, down=False, act=\"relu\", use_dropout=False\n",
    "        )\n",
    "        self.up7 = Block(features * 2 * 2, features, down=False, act=\"relu\", use_dropout=False)\n",
    "        self.final_up = nn.Sequential(\n",
    "            nn.ConvTranspose2d(features * 2, 3, kernel_size=4, stride=2, padding=1),\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        d1 = self.initial_down(x)\n",
    "        d2 = self.down1(d1)\n",
    "        d3 = self.down2(d2)\n",
    "        d4 = self.down3(d3)\n",
    "        d5 = self.down4(d4)\n",
    "        d6 = self.down5(d5)\n",
    "        d7 = self.down6(d6)\n",
    "        bottleneck = self.bottleneck(d7)\n",
    "        up1 = self.up1(bottleneck)\n",
    "        up2 = self.up2(torch.cat([up1, d7], 1))\n",
    "        up3 = self.up3(torch.cat([up2, d6], 1))\n",
    "        up4 = self.up4(torch.cat([up3, d5], 1))\n",
    "        up5 = self.up5(torch.cat([up4, d4], 1))\n",
    "        up6 = self.up6(torch.cat([up5, d3], 1))\n",
    "        up7 = self.up7(torch.cat([up6, d2], 1))\n",
    "        last = self.final_up(torch.cat([up7, d1], 1))\n",
    "        # print(\"last: \",last.shape)\n",
    "        return last"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disc = Discriminator(in_channels=10).to(device)\n",
    "gen = Generator(in_channels=10, features=64).to(device)\n",
    "opt_disc = optim.Adam(disc.parameters(), lr=2e-4, betas=(0.5, 0.999),)\n",
    "opt_gen = optim.Adam(gen.parameters(), lr=2e-4, betas=(0.5, 0.999))\n",
    "g_scaler = torch.cuda.amp.GradScaler()\n",
    "d_scaler = torch.cuda.amp.GradScaler()\n",
    "bce = nn.BCEWithLogitsLoss()\n",
    "l1_loss = nn.L1Loss()\n",
    "# Compute the Binary Cross Entropy loss with logits\n",
    "aux_criterion = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_acc(preds, labels):\n",
    "    correct = 0\n",
    "    preds_ = preds.argmax(dim=1)  # Get the index of the maximum predicted probability for each sample\n",
    "    # print(\"preds_: \",preds_)\n",
    "    # print(\"labels: \",labels)\n",
    "    correct = preds_.eq(labels).sum().item()  # Compare the indices with the target labels\n",
    "    # print(\"correct: \",correct)\n",
    "    acc = correct / len(labels) * 100.0  # Compute accuracy\n",
    "    # print(\"acc: \",acc)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_penalty(critic, labels, real, fake, img_size, device=\"cuda\"):\n",
    "    BATCH_SIZE, C, H, W = real.shape\n",
    "    alpha = torch.rand((BATCH_SIZE, 1, 1, 1)).repeat(1, C, H, W).to(device)\n",
    "    interpolated_images = real * alpha + fake * (1 - alpha)\n",
    "    # print(\"labels size: \",labels.shape)\n",
    "    # print(\"interpolated_images: \",interpolated_images.shape)\n",
    "    embed_disc=nn.Embedding(7, img_size*img_size).to(device)\n",
    "    embedding_disc=embed_disc(labels.long()) # Real Label given to discriminator\n",
    "    # print(\"embedding_disc: \",embedding_disc.shape)\n",
    "    \n",
    "    embedding_disc=embedding_disc.view(labels.shape[0],7,img_size,img_size)\n",
    "    real_disc = torch.cat([interpolated_images, embedding_disc], dim=1)\n",
    "    # print(\"real_disc: \",real_disc.shape)\n",
    "    # Calculate critic scores\n",
    "    mixed_scores = critic(real_disc)\n",
    "    # print(\"mixed_scores: \",len(mixed_scores))\n",
    "    # Take the gradient of the scores with respect to the images\n",
    "    grad_outputs = [torch.ones_like(score) for score in mixed_scores]\n",
    "    # print(\"grad_outputs: \",len(grad_outputs))\n",
    "    gradient = torch.autograd.grad(\n",
    "        inputs=interpolated_images,\n",
    "        outputs=mixed_scores,\n",
    "        grad_outputs=grad_outputs,\n",
    "        create_graph=True,\n",
    "        retain_graph=True\n",
    "    )[0]\n",
    "    gradient = gradient.view(gradient.shape[0], -1)\n",
    "    gradient_norm = gradient.norm(2, dim=1)\n",
    "    gradient_penalty = torch.mean((gradient_norm - 1) ** 2)\n",
    "    return gradient_penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 100\n",
    "L1_LAMBDA = 100\n",
    "CRITIC_ITERATIONS = 5\n",
    "LAMBDA_GP = 10\n",
    "\n",
    "# Set directory to save images\n",
    "save_dir = \"ACGAN_Unpaired\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "step = 0\n",
    "\n",
    "# Lists to store losses for plotting\n",
    "train_losses_D = []\n",
    "train_losses_G = []\n",
    "\n",
    "gen.train()\n",
    "disc.train()\n",
    "\n",
    "best_loss = float('inf')\n",
    "best_model_path = os.path.join(save_dir, \"best_model.pth\")\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "\n",
    "    # Initialize variables to accumulate losses over the epoch\n",
    "    epoch_train_loss_D = 0\n",
    "    epoch_train_loss_G = 0\n",
    "    epoch_train_loss_A = 0\n",
    "\n",
    "    for batch_idx, (labels, sketch,real,name,rand_labels) in enumerate(tqdm(dataloader)):\n",
    "        \n",
    "        \n",
    "        real = real.to(device)\n",
    "        noise= sketch.to(device)\n",
    "        labels = labels.to(device)\n",
    "        rand_labels = rand_labels.to(device).long()\n",
    "        # print(\"labels : \",labels)\n",
    "        # print(\"rand_labels: \",rand_labels)\n",
    "        img_size=256\n",
    "        \n",
    "        # Train Discriminator\n",
    "        with torch.cuda.amp.autocast():\n",
    "            embed_disc=nn.Embedding(7, img_size*img_size).to(device)\n",
    "            embedding_disc=embed_disc(labels.long()) # Real Label given to discriminator\n",
    "            # print(\"embedding_discs: \",embedding_disc.shape)\n",
    "            embedding_disc=embedding_disc.view(labels.shape[0],7,img_size,img_size)\n",
    "            real_disc = torch.cat([real, embedding_disc], dim=1)\n",
    "            \n",
    "            embed_gen = nn.Embedding(7, img_size*img_size).to(device)\n",
    "            embedding_gen = embed_gen(rand_labels) # Random Label to generator\n",
    "            \n",
    "            # print(\"embedding_gen: \",embedding_gen.shape)\n",
    "            # embedding_gen = embedding_gen.unsqueeze(3)\n",
    "            # upsampled_embedding_gen = F.interpolate(embedding_gen, size=(img_size,img_size), mode='nearest')\n",
    "            upsampled_embedding_gen=embedding_gen.view(labels.shape[0],7,img_size,img_size)\n",
    "            real_gen = torch.cat([noise, upsampled_embedding_gen], dim=1)\n",
    "            for _ in range(CRITIC_ITERATIONS):\n",
    "                disc.zero_grad()\n",
    "                y_fake = gen(real_gen) # Generate fake images\n",
    "                y_fake_conc=torch.cat([y_fake, embedding_disc], dim=1)\n",
    "                # print(\"y_fake: \",y_fake.shape)\n",
    "\n",
    "                # print(\"real_disc: \",real_disc.shape)\n",
    "                D_real,D_labels = disc(real_disc) # Discriminator with real images\n",
    "                dis_errD_real = bce(D_real, torch.ones_like(D_real)) # Loss with real images\n",
    "\n",
    "                # Assuming D_labels contains raw logits from the discriminator network\n",
    "                D_log_probs = nn.LogSoftmax(dim=1)(D_labels)\n",
    "                labels1 = labels.argmax(dim=1)\n",
    "                # print(\"D_labels: \",D_labels)\n",
    "                # print(\"labels: \",labels)\n",
    "                aux_errD_real = aux_criterion(D_log_probs, labels1) # Loss for labels\n",
    "                # print(\"aux_errD_real: \",aux_errD_real)\n",
    "                errD_real = dis_errD_real + aux_errD_real\n",
    "                errD_real.backward(retain_graph=True)\n",
    "                D_x = D_real.data.mean()\n",
    "                \n",
    "                # compute the current classification accuracy\n",
    "                accuracy = compute_acc(D_log_probs, labels1)\n",
    "\n",
    "\n",
    "                # print(\"y_fake: \",y_fake.shape)\n",
    "                # print(\"embedding_disc: \",embedding_disc.shape)\n",
    "                D_fake,D_fake_label = disc(y_fake_conc.detach()) # Discriminator with fake images\n",
    "                dis_errD_fake = bce(D_fake, torch.zeros_like(D_fake)) # Loss with fake images\n",
    "\n",
    "                D_log_probs_fake = nn.LogSoftmax(dim=1)(D_fake_label)\n",
    "                aux_errD_fake = aux_criterion(D_log_probs_fake, labels1 )\n",
    "\n",
    "                errD_fake = dis_errD_fake + aux_errD_fake\n",
    "                # disc.zero_grad()\n",
    "                # errD_fake.backward(retain_graph=True)\n",
    "                # D_G_z1 = D_fake.data.mean()\n",
    "                \n",
    "\n",
    "                gp = gradient_penalty(disc, labels, real, y_fake, img_size, device=device)\n",
    "                # opt_disc.step()\n",
    "                # errD = -(torch.mean(errD_real) - torch.mean(errD_fake)) + LAMBDA_GP * gp\n",
    "                errD = (errD_real + errD_fake)/2 + LAMBDA_GP * gp\n",
    "\n",
    "                # D_loss = (D_real_loss + D_fake_loss) / 2\n",
    "                \n",
    "                d_scaler.scale(errD).backward(retain_graph=True)\n",
    "                d_scaler.step(opt_disc)\n",
    "                d_scaler.update()\n",
    "\n",
    "        # Train Generator\n",
    "            gen.zero_grad()\n",
    "            D_fake, D_gen_label = disc(y_fake_conc)\n",
    "            dis_errG = bce(D_fake, torch.ones_like(D_fake))\n",
    "            # print(\"D_gen_label: \",D_gen_label)\n",
    "            # print(\"labels: \",labels)\n",
    "\n",
    "            D_log_probs_1 = nn.LogSoftmax(dim=1)(D_gen_label)\n",
    "            aux_errG = aux_criterion(D_log_probs_1, labels1)\n",
    "\n",
    "            L1 = l1_loss(y_fake, real) * L1_LAMBDA\n",
    "            # L1 = l1_loss(y_fake, real)\n",
    "            # ms_ssim_loss = 1 - ms_ssim( y_fake, real, data_range=1, size_average=True )\n",
    "            # print(y_fake)\n",
    "            # print(\"ms_ssim_loss: \",ms_ssim_loss)\n",
    "            # print(\"L1: \",L1)\n",
    "            # print(\"aux_errG: \",aux_errG)\n",
    "            # print(\"dis_errG: \",dis_errG)\n",
    "            errG = dis_errG + aux_errG + L1 \n",
    "            # errG.backward(retain_graph=True)\n",
    "            # D_G_z2 = D_fake.data.mean()\n",
    "            # opt_gen.step()\n",
    "\n",
    "            # # print(\"y_fake: \",y_fake.shape)\n",
    "            # # print(\"real: \",real.shape)\n",
    "            # L1 = l1_loss(y_fake, real) * L1_LAMBDA\n",
    "            # G_loss = G_fake_loss + L1\n",
    "\n",
    "            opt_gen.zero_grad()\n",
    "            g_scaler.scale(errG).backward(retain_graph=True)\n",
    "            g_scaler.step(opt_gen)\n",
    "            g_scaler.update()\n",
    "\n",
    "        if batch_idx % 50 == 0:\n",
    "            with torch.no_grad():\n",
    "                fake = gen(real_gen)\n",
    "        \n",
    "               # Create grid containing both real and fake images\n",
    "                img_grid = torch.cat((real[:8], fake[:8], noise[:8]), dim=0)\n",
    "                \n",
    "                # Make grid for visualization\n",
    "                img_grid = torchvision.utils.make_grid(img_grid, nrow=8, normalize=True)\n",
    "\n",
    "                # fid = FrechetInceptionDistance(feature=64)\n",
    "                # fid.update(real, real=True)\n",
    "                # fid.update(fake, real=False)\n",
    "\n",
    "                # Save the generated fake images locally\n",
    "                torchvision.utils.save_image(img_grid, os.path.join(save_dir, f\"epoch_{epoch}_batch_{batch_idx}.png\"))\n",
    "\n",
    "            print(\n",
    "                f\"Epoch [{epoch}/{NUM_EPOCHS}] Batch {batch_idx}/{len(dataloader)} \\\n",
    "                  Loss D: {errD:.4f}, loss G: {errG:.4f}, label accuracy: {accuracy:.4f}\"\n",
    "            )\n",
    "\n",
    "            step += 1\n",
    "\n",
    "        # Accumulate losses\n",
    "        epoch_train_loss_D += errD.item()\n",
    "        epoch_train_loss_G += errG.item()\n",
    "        epoch_train_loss_A += accuracy\n",
    "\n",
    "    # Calculate average training losses for the epoch\n",
    "    avg_train_loss_D = epoch_train_loss_D / len(dataloader)\n",
    "    avg_train_loss_G = epoch_train_loss_G / len(dataloader)\n",
    "\n",
    "    # Store the average training losses for plotting\n",
    "    train_losses_D.append(avg_train_loss_D)\n",
    "    train_losses_G.append(avg_train_loss_G)\n",
    "\n",
    "\n",
    "    # Save the model if it has the best performance on the training set\n",
    "    if avg_train_loss_G < best_loss:\n",
    "        best_loss = avg_train_loss_G\n",
    "        torch.save(gen.state_dict(), best_model_path)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot the training curves\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(train_losses_D, label='Train D loss')\n",
    "plt.plot(train_losses_G, label='Train G loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Curve')\n",
    "plt.legend()\n",
    "plt.savefig(os.path.join(save_dir, \"training_curve.png\"))\n",
    "plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "idf1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
